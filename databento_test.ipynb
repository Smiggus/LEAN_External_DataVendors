{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataBento Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' DataBento Downloader\n",
    "    Downloads the tickers within the tickers[] list. Saves them locally to a CSV file.\n",
    "'''\n",
    "### Region Imports ###\n",
    "import databento as db\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "### End Region Imports ###\n",
    "\n",
    "# Initialize Data Bento client\n",
    "client = db.Historical(os.getenv('databento_api_key'))\n",
    "\n",
    "# Example tickers and date range\n",
    "tickers = ['SPY']\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-09-01'\n",
    "\n",
    "for ticker in tickers:\n",
    "    dataset = client.timeseries.get_range(\n",
    "        dataset=\"XNAS.ITCH\",\n",
    "        symbols=ticker,\n",
    "        start=start_date,\n",
    "        end=end_date,\n",
    "        schema='ohlcv-1d'\n",
    "    )\n",
    "    dataset.to_csv(f'databento/downloads/{ticker}_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converter Method\n",
    "Working as of 26SEP24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "ticker = 'SPY'\n",
    "def convert_to_lean_format(csv_file, ticker, frequency='daily'):\n",
    "    \"\"\"\n",
    "    Converts a CSV file containing stock data into a format compatible with LEAN Local CLI Framework.\n",
    "    Args:\n",
    "        csv_file (str): The path to the input CSV file containing stock data.\n",
    "        ticker (str): The stock ticker symbol.\n",
    "        frequency (str, optional): The frequency of the data. Can be 'daily', 'hourly', or 'minute'. Defaults to 'daily'.\n",
    "    Returns:\n",
    "        None: The function saves the converted data to a file in the appropriate directory based on the frequency. Located within project directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['date'] = pd.to_datetime(df.pop('ts_event')).dt.strftime('%Y%m%d %H:%M')\n",
    "    df = df[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    \n",
    "    # Conversion from dollars to deci-cents\n",
    "    df[['open', 'high', 'low', 'close']] = (df[['open', 'high', 'low', 'close']] * 10000).astype(int)\n",
    "    \n",
    "    # Data type sorting for directory saving for csv\n",
    "    if frequency == 'daily':\n",
    "        output_dir = 'data/equity/usa/daily/'\n",
    "        output_file = f\"{output_dir}{ticker.lower()}.csv\"\n",
    "    elif frequency == 'hourly':\n",
    "        output_dir = 'data/equity/usa/hourly/'\n",
    "        output_file = f\"{output_dir}{ticker.lower()}.csv\"\n",
    "    else:\n",
    "        output_dir = 'data/equity/usa/minute/'\n",
    "        output_file = f\"{output_dir}{(ticker.lower())}.csv\"\n",
    "    \n",
    "    df.to_csv(output_file, index=False, header=False)\n",
    "    \n",
    "    # Zip File\n",
    "    zip_file = os.path.join(output_dir, f'{ticker.lower()}.zip')\n",
    "    #zip_file = os.path.join(\"./\", f'{ticker.lower()}.zip')\n",
    "    #zip_fileblank = f'{ticker.lower()}.zip'\n",
    "    # Create a zip file and add the csv file to it\n",
    "    with zipfile.ZipFile(zip_file, 'w') as zf:\n",
    "        zf.write(output_file, arcname=f'{ticker.lower()}.csv')\n",
    "\n",
    "    # Optionally, remove the csv file after zipping (if you want the zip to be the only output)\n",
    "    #os.remove(csv_file)\n",
    "\n",
    "    print(f\"{output_file} has been successfully zipped into {zip_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/equity/usa/daily/spy.csv has been successfully zipped into data/equity/usa/daily/spy.zip.\n"
     ]
    }
   ],
   "source": [
    "csv_file = f'databento/downloads/{ticker}_data.csv'\n",
    "frequency = 'daily'\n",
    "convert_to_lean_format(csv_file, ticker, frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined file, downloads then converts using databento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'databento/downloads/QQQ_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Example ticker list and date range\u001b[39;00m\n\u001b[0;32m     67\u001b[0m ticker_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQQQ\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 68\u001b[0m \u001b[43mdownload_and_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2024-01-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2024-06-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdaily\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[52], line 61\u001b[0m, in \u001b[0;36mdownload_and_convert\u001b[1;34m(tickers, start_date, end_date, frequency)\u001b[0m\n\u001b[0;32m     53\u001b[0m dataset \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mtimeseries\u001b[38;5;241m.\u001b[39mget_range(\n\u001b[0;32m     54\u001b[0m     dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXNAS.ITCH\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m     symbols\u001b[38;5;241m=\u001b[39mticker,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mohlcv-1d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     59\u001b[0m )\n\u001b[0;32m     60\u001b[0m csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatabento/downloads/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 61\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Convert to QuantConnect format\u001b[39;00m\n\u001b[0;32m     64\u001b[0m convert_to_lean_format(csv_file, ticker, frequency)\n",
      "File \u001b[1;32mc:\\Users\\MP\\anaconda3\\envs\\lean_datafeed\\Lib\\site-packages\\databento\\common\\dbnstore.py:833\u001b[0m, in \u001b[0;36mDBNStore.to_csv\u001b[1;34m(self, path, pretty_px, pretty_ts, map_symbols, compression, schema)\u001b[0m\n\u001b[0;32m    830\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma schema must be specified for mixed DBN data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    831\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema\n\u001b[1;32m--> 833\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m output:\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transcode(\n\u001b[0;32m    835\u001b[0m         output\u001b[38;5;241m=\u001b[39moutput,\n\u001b[0;32m    836\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mEncoding\u001b[38;5;241m.\u001b[39mCSV,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    841\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m    842\u001b[0m     )\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'databento/downloads/QQQ_data.csv'"
     ]
    }
   ],
   "source": [
    "import databento as db\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def convert_to_lean_format(csv_file, ticker, frequency='daily'):\n",
    "    \"\"\"\n",
    "    Converts a CSV file containing stock data into a format compatible with LEAN Local CLI Framework.\n",
    "    Args:\n",
    "        csv_file (str): The path to the input CSV file containing stock data.\n",
    "        ticker (str): The stock ticker symbol.\n",
    "        frequency (str, optional): The frequency of the data. Can be 'daily', 'hourly', or 'minute'. Defaults to 'daily'.\n",
    "    Returns:\n",
    "        None: The function saves the converted data to a file in the appropriate directory based on the frequency. Located within project directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['date'] = pd.to_datetime(df.pop('ts_event')).dt.strftime('%Y%m%d %H:%M')\n",
    "    df = df[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    \n",
    "    # Conversion from dollars to deci-cents\n",
    "    df[['open', 'high', 'low', 'close']] = (df[['open', 'high', 'low', 'close']] * 10000).astype(int)\n",
    "    \n",
    "    # Data type sorting for directory saving for csv\n",
    "    if frequency == 'daily':\n",
    "        output_dir = 'data/equity/usa/daily/'\n",
    "        output_file = f\"{output_dir}{ticker.lower()}.csv\"\n",
    "    elif frequency == 'hourly':\n",
    "        output_dir = 'data/equity/usa/hourly/'\n",
    "        output_file = f\"{output_dir}{ticker.lower()}.csv\"\n",
    "    else:\n",
    "        output_dir = 'data/equity/usa/minute/'\n",
    "        output_file = f\"{output_dir}{(ticker.lower())}.csv\"\n",
    "    \n",
    "    df.to_csv(output_file, index=False, header=False)\n",
    "    \n",
    "    # Zip File\n",
    "    zip_file = os.path.join(output_dir, f'{ticker.lower()}.zip')\n",
    "    #zip_file = os.path.join(\"./\", f'{ticker.lower()}.zip')\n",
    "    #zip_fileblank = f'{ticker.lower()}.zip'\n",
    "    # Create a zip file and add the csv file to it\n",
    "    with zipfile.ZipFile(zip_file, 'w') as zf:\n",
    "        zf.write(output_file, arcname=f'{ticker.lower()}.csv')\n",
    "\n",
    "    # Optionally, remove the csv file after zipping (if you want the zip to be the only output)\n",
    "    #os.remove(csv_file)\n",
    "\n",
    "    print(f\"{output_file} has been successfully zipped into {zip_file}.\")\n",
    "    \n",
    "def download_and_convert(tickers, start_date, end_date, frequency='daily'):\n",
    "    # Initialize Data Bento client\n",
    "    client = db.Historical(os.getenv('databento_api_key'))\n",
    "    for ticker in tickers:\n",
    "        dataset = client.timeseries.get_range(\n",
    "            dataset=\"XNAS.ITCH\",\n",
    "            symbols=ticker,\n",
    "            start=start_date,\n",
    "            end=end_date,\n",
    "            schema='ohlcv-1d'\n",
    "        )\n",
    "        csv_file = f'databento/downloads/{ticker}_data.csv'\n",
    "        dataset.to_csv(csv_file)\n",
    "\n",
    "        # Convert to QuantConnect format\n",
    "        convert_to_lean_format(csv_file, ticker, frequency)\n",
    "\n",
    "# Example ticker list and date range\n",
    "ticker_list = ['QQQ']\n",
    "download_and_convert(ticker_list, '2024-01-01', '2024-06-01', 'daily')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lean_datafeed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
