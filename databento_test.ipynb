{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataBento Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' DataBento Downloader\n",
    "    Downloads the tickers within the tickers[] list. Saves them locally to a CSV file.\n",
    "'''\n",
    "### Region Imports ###\n",
    "import databento as db\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "### End Region Imports ###\n",
    "\n",
    "# Initialize Data Bento client\n",
    "client = db.Historical(os.getenv('databento_api_key'))\n",
    "\n",
    "# Example tickers and date range\n",
    "tickers = ['SPY']\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-09-01'\n",
    "\n",
    "for ticker in tickers:\n",
    "    dataset = client.timeseries.get_range(\n",
    "        dataset=\"XNAS.ITCH\",\n",
    "        symbols=ticker,\n",
    "        start=start_date,\n",
    "        end=end_date,\n",
    "        schema='ohlcv-1d'\n",
    "    )\n",
    "    dataset.to_csv(f'databento/downloads/{ticker}_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converter Method\n",
    "Working as of 26SEP24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "ticker = 'SPY'\n",
    "def convert_to_lean_format(csv_file, ticker, frequency='daily'):\n",
    "    \"\"\"\n",
    "    Converts a CSV file containing stock data into a format compatible with LEAN Local CLI Framework.\n",
    "    Args:\n",
    "        csv_file (str): The path to the input CSV file containing stock data.\n",
    "        ticker (str): The stock ticker symbol.\n",
    "        frequency (str, optional): The frequency of the data. Can be 'daily', 'hourly', or 'minute'. Defaults to 'daily'.\n",
    "    Returns:\n",
    "        None: The function saves the converted data to a file in the appropriate directory based on the frequency. Located within project directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['date'] = pd.to_datetime(df.pop('ts_event')).dt.strftime('%Y%m%d %H:%M')\n",
    "    df = df[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    \n",
    "    # Conversion from dollars to deci-cents\n",
    "    df[['open', 'high', 'low', 'close']] = (df[['open', 'high', 'low', 'close']] * 10000).astype(int)\n",
    "    \n",
    "    # Data type sorting for directory saving for csv\n",
    "    if frequency == 'daily':\n",
    "        output_dir = 'data/equity/usa/daily/'\n",
    "        output_file = f\"{output_dir}{ticker.lower()}.csv\"\n",
    "    elif frequency == 'hourly':\n",
    "        output_dir = 'data/equity/usa/hourly/'\n",
    "        output_file = f\"{output_dir}{ticker.lower()}.csv\"\n",
    "    else:\n",
    "        output_dir = 'data/equity/usa/minute/'\n",
    "        output_file = f\"{output_dir}{(ticker.lower())}.csv\"\n",
    "    \n",
    "    df.to_csv(output_file, index=False, header=False)\n",
    "    \n",
    "    # Zip File\n",
    "    zip_file = os.path.join(output_dir, f'{ticker.lower()}.zip')\n",
    "    #zip_file = os.path.join(\"./\", f'{ticker.lower()}.zip')\n",
    "    #zip_fileblank = f'{ticker.lower()}.zip'\n",
    "    # Create a zip file and add the csv file to it\n",
    "    with zipfile.ZipFile(zip_file, 'w') as zf:\n",
    "        zf.write(output_file, arcname=f'{ticker.lower()}.csv')\n",
    "\n",
    "    # Optionally, remove the csv file after zipping (if you want the zip to be the only output)\n",
    "    #os.remove(csv_file)\n",
    "\n",
    "    print(f\"{output_file} has been successfully zipped into {zip_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/equity/usa/daily/spy.csv has been successfully zipped into data/equity/usa/daily/spy.zip.\n"
     ]
    }
   ],
   "source": [
    "csv_file = f'databento/downloads/{ticker}_data.csv'\n",
    "frequency = 'daily'\n",
    "convert_to_lean_format(csv_file, ticker, frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined file, downloads then converts using databento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/equity/usa/daily/qqq.csv has been successfully zipped into data/equity/usa/daily/qqq.zip.\n"
     ]
    }
   ],
   "source": [
    "import databento as db\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "def convert_to_lean_format(csv_file, ticker, frequency='daily'):\n",
    "    \"\"\"\n",
    "    Converts a CSV file containing stock data into a format compatible with LEAN Local CLI Framework.\n",
    "    Args:\n",
    "        csv_file (str): The path to the input CSV file containing stock data.\n",
    "        ticker (str): The stock ticker symbol.\n",
    "        frequency (str, optional): The frequency of the data. Can be 'daily', 'hourly', or 'minute'. Defaults to 'daily'.\n",
    "    Returns:\n",
    "        None: The function saves the converted data to a file in the appropriate directory based on the frequency. Located within project directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['date'] = pd.to_datetime(df.pop('ts_event')).dt.strftime('%Y%m%d %H:%M')\n",
    "    df = df[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    \n",
    "    # Conversion from dollars to deci-cents\n",
    "    df[['open', 'high', 'low', 'close']] = (df[['open', 'high', 'low', 'close']] * 10000).astype(int)\n",
    "    \n",
    "    # Data type sorting for directory saving for csv\n",
    "    if frequency == 'daily':\n",
    "        output_dir = 'data/equity/usa/daily/'\n",
    "        output_file = f\"{output_dir}{ticker.lower()}.csv\"\n",
    "    elif frequency == 'hourly':\n",
    "        output_dir = 'data/equity/usa/hourly/'\n",
    "        output_file = f\"{output_dir}{ticker.lower()}.csv\"\n",
    "    else:\n",
    "        output_dir = 'data/equity/usa/minute/'\n",
    "        output_file = f\"{output_dir}{(ticker.lower())}.csv\"\n",
    "    \n",
    "    df.to_csv(output_file, index=False, header=False)\n",
    "    \n",
    "    # Zip File\n",
    "    zip_file = os.path.join(output_dir, f'{ticker.lower()}.zip')\n",
    "    #zip_file = os.path.join(\"./\", f'{ticker.lower()}.zip')\n",
    "    #zip_fileblank = f'{ticker.lower()}.zip'\n",
    "    # Create a zip file and add the csv file to it\n",
    "    with zipfile.ZipFile(zip_file, 'w') as zf:\n",
    "        zf.write(output_file, arcname=f'{ticker.lower()}.csv')\n",
    "\n",
    "    # Optionally, remove the csv file after zipping (if you want the zip to be the only output)\n",
    "    #os.remove(csv_file)\n",
    "\n",
    "    print(f\"{output_file} has been successfully zipped into {zip_file}.\")\n",
    "    \n",
    "def download_and_convert(tickers, start_date, end_date, frequency='daily'):\n",
    "    # Initialize Data Bento client with .env variable api key\n",
    "    client = db.Historical(os.getenv('databento_api_key'))\n",
    "    \n",
    "    # Loop through tickers within ticker list\n",
    "    for ticker in tickers:\n",
    "        # CSV File variable\n",
    "        csv_file = f'databento/downloads/{ticker}_data.csv'\n",
    "        # Remove the existing file if it exists\n",
    "        if os.path.exists(csv_file):\n",
    "            # open the file and get the dates\n",
    "            os.remove(csv_file)\n",
    "            \n",
    "        dataset = client.timeseries.get_range(\n",
    "            dataset=\"XNAS.ITCH\",\n",
    "            symbols=ticker,\n",
    "            start=start_date,\n",
    "            end=end_date,\n",
    "            schema='ohlcv-1d'\n",
    "        )\n",
    "        \n",
    "        dataset.to_csv(csv_file)\n",
    "        # Insert new download and append data logic here\n",
    "        \n",
    "        # Convert to QuantConnect format\n",
    "        convert_to_lean_format(csv_file, ticker, frequency)\n",
    "\n",
    "# Example ticker list and date range\n",
    "ticker_list = ['QQQ']\n",
    "download_and_convert(ticker_list, '2024-01-01', '2024-06-01', 'daily')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is working as of 28SEP24\n",
    "\n",
    "The below contains logic to download and append data if required. The lean converter shouldnt need any amendments, it handles the whole dataset anyway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker QQQ already up-to-date\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'QQQ'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import databento as db\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "def get_data_from_databento(ticker, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetches OHLCV data for a given ticker from Data Bento for the specified date range.\n",
    "    Args:\n",
    "        ticker (str): The stock ticker symbol.\n",
    "        start_date (datetime): The start date of the data to retrieve.\n",
    "        end_date (datetime): The end date of the data to retrieve.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the retrieved data.\n",
    "    \"\"\"\n",
    "    client = db.Historical(os.getenv('databento_api_key'))\n",
    "    dataset = client.timeseries.get_range(\n",
    "        dataset=\"XNAS.ITCH\",\n",
    "        symbols=ticker,\n",
    "        start=start_date.strftime('%Y-%m-%d'),\n",
    "        end=end_date.strftime('%Y-%m-%d'),\n",
    "        schema='ohlcv-1d'\n",
    "    )\n",
    "    df = dataset.to_df()\n",
    "    return df\n",
    "\n",
    "def download_and_append_data(ticker, start_date, end_date, folder='databento/downloads'):\n",
    "    \"\"\"\n",
    "    Downloads and appends stock data from Data Bento API if necessary.\n",
    "    Args:\n",
    "        ticker (str): The stock ticker symbol.\n",
    "        start_date (str): The start date for data retrieval.\n",
    "        end_date (str): The end date for data retrieval.\n",
    "        folder (str): Folder to save the CSV file.\n",
    "    \n",
    "    Returns:\n",
    "        str: The ticker symbol.\n",
    "    \"\"\"\n",
    "    # Define file path for the ticker\n",
    "    fname = ticker.lower() + '.csv'\n",
    "    path = Path(folder) / fname\n",
    "\n",
    "    # Convert start_date and end_date to datetime objects\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if path.exists():\n",
    "        # Open the file and retrieve existing dates\n",
    "        df_existing = pd.read_csv(path, index_col=0)\n",
    "        dates = pd.DatetimeIndex(df_existing.index.sort_values(ascending=True))\n",
    "                \n",
    "        # Convert the existing dates to tz-naive (remove timezone). Decide whether to keep this or get tz info\n",
    "        dates = dates.tz_localize(None)\n",
    "    else:\n",
    "        dates = None\n",
    "\n",
    "    # If no file or date range is not covered\n",
    "    if dates is None or start_date < dates[0] or end_date > dates[-1]:\n",
    "        print(f'Fetching data for {ticker} from {start_date} to {end_date}')\n",
    "        \n",
    "        # Attempt to fetch new data from Data Bento\n",
    "        try:\n",
    "            # Add buffer (delta) to the date range to handle overlaps\n",
    "            delta = timedelta(days=3)\n",
    "            df_new = get_data_from_databento(ticker, start_date - delta, end_date + delta)\n",
    "            \n",
    "            # If file exists, append new data\n",
    "            if path.exists():\n",
    "                df_combined = pd.concat([df_existing, df_new]).drop_duplicates()\n",
    "                df_combined.sort_index(inplace=True)\n",
    "                df_combined.to_csv(path)\n",
    "            else:\n",
    "                # Save the new data if no file exists\n",
    "                df_new.to_csv(path)\n",
    "            print(f'Ticker {ticker} data saved to {path}')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Error fetching data for {ticker}: {e}')\n",
    "            return None\n",
    "    else:\n",
    "        print(f'Ticker {ticker} already up-to-date')\n",
    "\n",
    "    return ticker\n",
    "\n",
    "# Example usage\n",
    "download_and_append_data('QQQ', '2024-01-01', '2024-06-01')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Integrated Pipeline\n",
    "28SEP24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for QQQ from 2022-12-01 00:00:00 to 2022-12-01 00:00:00\n",
      "Ticker QQQ data saved to databento\\downloads\\QQQ_data.csv\n",
      "data/equity/usa/daily/qqq.csv has been successfully zipped into data/equity/usa/daily/qqq.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'QQQ'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import databento as db\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def get_data_from_databento(ticker, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetches OHLCV data for a given ticker from Data Bento for the specified date range.\n",
    "    Args:\n",
    "        ticker (str): The stock ticker symbol.\n",
    "        start_date (datetime): The start date of the data to retrieve.\n",
    "        end_date (datetime): The end date of the data to retrieve.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the retrieved data.\n",
    "    \"\"\"\n",
    "    client = db.Historical(os.getenv('databento_api_key'))\n",
    "    dataset = client.timeseries.get_range(\n",
    "        dataset=\"XNAS.ITCH\",\n",
    "        symbols=ticker,\n",
    "        start=start_date.strftime('%Y-%m-%d'),\n",
    "        end=end_date.strftime('%Y-%m-%d'),\n",
    "        schema='ohlcv-1d'\n",
    "    )\n",
    "    \n",
    "    df = dataset.to_df()\n",
    "    return df\n",
    "\n",
    "def convert_to_lean_format(csv_file, ticker, frequency='daily'):\n",
    "    \"\"\"\n",
    "    Converts a CSV file containing stock data into a format compatible with LEAN Local CLI Framework.\n",
    "    Args:\n",
    "        csv_file (str): The path to the input CSV file containing stock data.\n",
    "        ticker (str): The stock ticker symbol.\n",
    "        frequency (str, optional): The frequency of the data. Can be 'daily', 'hourly', or 'minute'. Defaults to 'daily'.\n",
    "    Returns:\n",
    "        None: The function saves the converted data to a file in the appropriate directory based on the frequency. Located within project directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['date'] = pd.to_datetime(df.pop('ts_event')).dt.strftime('%Y%m%d %H:%M')\n",
    "    df = df[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    \n",
    "    # Conversion from dollars to deci-cents\n",
    "    df[['open', 'high', 'low', 'close']] = (df[['open', 'high', 'low', 'close']] * 10000).astype(int)\n",
    "    \n",
    "    # Data type sorting for directory saving for csv\n",
    "    if frequency == 'daily':\n",
    "        output_dir = 'data/equity/usa/daily/'\n",
    "        output_file = f\"{output_dir}{ticker.lower()}.csv\"\n",
    "    elif frequency == 'hourly':\n",
    "        output_dir = 'data/equity/usa/hourly/'\n",
    "        output_file = f\"{output_dir}{ticker.lower()}.csv\"\n",
    "    else:\n",
    "        output_dir = 'data/equity/usa/minute/'\n",
    "        output_file = f\"{output_dir}{(ticker.lower())}.csv\"\n",
    "    \n",
    "    df.to_csv(output_file, index=False, header=False)\n",
    "    \n",
    "    # Zip File\n",
    "    zip_file = os.path.join(output_dir, f'{ticker.lower()}.zip')\n",
    "    \n",
    "    # Create a zip file and add the csv file to it\n",
    "    with zipfile.ZipFile(zip_file, 'w') as zf:\n",
    "        zf.write(output_file, arcname=f'{ticker.lower()}.csv')\n",
    "\n",
    "    print(f\"{output_file} has been successfully zipped into {zip_file}.\")\n",
    "    \n",
    "def download_and_append_data(ticker, start_date, end_date, folder='databento/downloads', frequency='daily'):\n",
    "    \"\"\"\n",
    "    Downloads and appends stock data from Data Bento API if necessary, then converts the data to QuantConnect format.\n",
    "    Args:\n",
    "        ticker (str): The stock ticker symbol.\n",
    "        start_date (str): The start date for data retrieval.\n",
    "        end_date (str): The end date for data retrieval.\n",
    "        folder (str): Folder to save the CSV file.\n",
    "        frequency (str): Data frequency ('daily', 'hourly', 'minute').\n",
    "    \n",
    "    Returns:\n",
    "        str: The ticker symbol.\n",
    "    \"\"\"\n",
    "    # Define file path for the ticker - Saves the databento download file\n",
    "    #fname = ticker.lower() + '.csv'\n",
    "    fname = f'{ticker}_data.csv'\n",
    "    path = Path(folder) / fname\n",
    "\n",
    "    # Convert start_date and end_date to datetime objects\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if path.exists():\n",
    "        # Open the file and retrieve existing dates\n",
    "        df_existing = pd.read_csv(path, index_col=0)\n",
    "        df_existing.index = pd.to_datetime(df_existing.index)  # Ensure the index is converted to Timestamps\n",
    "        dates = pd.DatetimeIndex(df_existing.index.sort_values(ascending=True))\n",
    "        \n",
    "        # Convert the existing dates to tz-naive (remove timezone)\n",
    "        dates = dates.tz_localize(None)\n",
    "    else:\n",
    "        dates = None\n",
    "\n",
    "    # If no file or date range is not covered\n",
    "    if dates is None or start_date < dates[0] or end_date > dates[-1]:\n",
    "        print(f'Fetching data for {ticker} from {start_date} to {end_date}')\n",
    "        \n",
    "        # Attempt to fetch new data from Data Bento\n",
    "        try:\n",
    "            # Add buffer (delta) to the date range to handle overlaps\n",
    "            delta = timedelta(days=3)\n",
    "            df_new = get_data_from_databento(ticker, start_date - delta, end_date + delta)\n",
    "                        \n",
    "            # If file exists, append new data\n",
    "            if path.exists():\n",
    "                df_combined = pd.concat([df_existing, df_new]).drop_duplicates()\n",
    "                df_combined.sort_index(inplace=True)\n",
    "                df_combined.to_csv(path)\n",
    "            else:\n",
    "                # Save the new data if no file exists\n",
    "                df_new.to_csv(path)\n",
    "            print(f'Ticker {ticker} data saved to {path}')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Error fetching data for {ticker}: {e}')\n",
    "            return None\n",
    "    else:\n",
    "        print(f'Ticker {ticker} already up-to-date')\n",
    "\n",
    "    # Convert to QuantConnect format (path = path to csv file incl. .csv, ticker = ticker symbol, frequency = 'daily', 'hourly', 'minute')\n",
    "    convert_to_lean_format(path, ticker, frequency)\n",
    "\n",
    "    return ticker\n",
    "\n",
    "# Example usage\n",
    "download_and_append_data('QQQ', '2022-12-01', '2022-12-01')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working, now next test in QC localdatatestspy\n",
    "Also figure out why the file gets saved to databento\\downloads AND the target folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing convert_utc_to_ny time\n",
    "def convert_utc_to_ny(df, datetime_column='ts_event'):\n",
    "    \"\"\"\n",
    "    Convert a datetime column from UTC to New York time (Eastern Time).\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the datetime column in UTC.\n",
    "        datetime_column (str): The name of the datetime column to be converted. Defaults to 'ts_event'.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the converted New York time column.\n",
    "    \"\"\"\n",
    "    # Ensure the datetime column is in UTC timezone\n",
    "    df[datetime_column] = pd.to_datetime(df[datetime_column])\n",
    "    try:\n",
    "        df[datetime_column] = df[datetime_column].dt.tz_localize('UTC')  # Localize to UTC\n",
    "    except:\n",
    "        # Do nothing, we want it to convert first\n",
    "        pass\n",
    "    # Convert the UTC time to New York time (Eastern Time)\n",
    "    df[datetime_column] = df[datetime_column].dt.tz_convert('America/New_York')\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('databento/downloads/QQQ_data.csv')\n",
    "df_ny = convert_utc_to_ny(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_event</th>\n",
       "      <th>rtype</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>instrument_id</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-29 19:00:00-05:00</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>8933</td>\n",
       "      <td>281.65</td>\n",
       "      <td>294.20</td>\n",
       "      <td>279.97</td>\n",
       "      <td>294.00</td>\n",
       "      <td>13716247.0</td>\n",
       "      <td>QQQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-30 19:00:00-05:00</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>8929</td>\n",
       "      <td>293.00</td>\n",
       "      <td>295.75</td>\n",
       "      <td>290.88</td>\n",
       "      <td>293.24</td>\n",
       "      <td>8271505.0</td>\n",
       "      <td>QQQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-01 19:00:00-05:00</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>8919</td>\n",
       "      <td>293.43</td>\n",
       "      <td>293.94</td>\n",
       "      <td>286.00</td>\n",
       "      <td>291.94</td>\n",
       "      <td>9893054.0</td>\n",
       "      <td>QQQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-04 19:00:00-05:00</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>8916</td>\n",
       "      <td>292.04</td>\n",
       "      <td>292.26</td>\n",
       "      <td>286.15</td>\n",
       "      <td>288.02</td>\n",
       "      <td>6803353.0</td>\n",
       "      <td>QQQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-05 19:00:00-05:00</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>8915</td>\n",
       "      <td>288.28</td>\n",
       "      <td>288.58</td>\n",
       "      <td>280.26</td>\n",
       "      <td>282.15</td>\n",
       "      <td>9180658.0</td>\n",
       "      <td>QQQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ts_event  rtype  publisher_id  instrument_id    open  \\\n",
       "0 2022-11-29 19:00:00-05:00     35             2           8933  281.65   \n",
       "1 2022-11-30 19:00:00-05:00     35             2           8929  293.00   \n",
       "2 2022-12-01 19:00:00-05:00     35             2           8919  293.43   \n",
       "3 2022-12-04 19:00:00-05:00     35             2           8916  292.04   \n",
       "4 2022-12-05 19:00:00-05:00     35             2           8915  288.28   \n",
       "\n",
       "     high     low   close      volume symbol  \n",
       "0  294.20  279.97  294.00  13716247.0    QQQ  \n",
       "1  295.75  290.88  293.24   8271505.0    QQQ  \n",
       "2  293.94  286.00  291.94   9893054.0    QQQ  \n",
       "3  292.26  286.15  288.02   6803353.0    QQQ  \n",
       "4  288.58  280.26  282.15   9180658.0    QQQ  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ny.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "\n",
    "def upload_to_postgresql(df, ticker, schema='databento_ohlcv'):\n",
    "    \"\"\"\n",
    "    Uploads a DataFrame to a PostgreSQL database using SQLAlchemy.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing OHLCV data.\n",
    "        ticker (str): The stock ticker symbol (used to name the table).\n",
    "        schema (str): The schema where the table should be created. Default is 'databento_ohlcv'.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Fetch credentials from environment variables\n",
    "    pguser = os.getenv('pguser')\n",
    "    pgpass = os.getenv('pgpass')\n",
    "    pghost = os.getenv('pghost')\n",
    "    \n",
    "    # Database connection URL using environment variables\n",
    "    db_url = f'postgresql://{pguser}:{pgpass}@{pghost}/FinancialData'\n",
    "    engine = create_engine(db_url)\n",
    "\n",
    "    try:\n",
    "        # Write the DataFrame to the PostgreSQL table\n",
    "        df.to_sql(ticker, engine, schema=schema, if_exists='replace', index=False)\n",
    "        print(f\"Data for {ticker} uploaded successfully to {schema}.{ticker}.\")\n",
    "    \n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"Error uploading data for {ticker} to PostgreSQL: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_event</th>\n",
       "      <th>rtype</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>instrument_id</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-30 00:00:00+00:00</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>8933</td>\n",
       "      <td>281.65</td>\n",
       "      <td>294.20</td>\n",
       "      <td>279.97</td>\n",
       "      <td>294.00</td>\n",
       "      <td>13716247.0</td>\n",
       "      <td>QQQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-01 00:00:00+00:00</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>8929</td>\n",
       "      <td>293.00</td>\n",
       "      <td>295.75</td>\n",
       "      <td>290.88</td>\n",
       "      <td>293.24</td>\n",
       "      <td>8271505.0</td>\n",
       "      <td>QQQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-02 00:00:00+00:00</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>8919</td>\n",
       "      <td>293.43</td>\n",
       "      <td>293.94</td>\n",
       "      <td>286.00</td>\n",
       "      <td>291.94</td>\n",
       "      <td>9893054.0</td>\n",
       "      <td>QQQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-05 00:00:00+00:00</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>8916</td>\n",
       "      <td>292.04</td>\n",
       "      <td>292.26</td>\n",
       "      <td>286.15</td>\n",
       "      <td>288.02</td>\n",
       "      <td>6803353.0</td>\n",
       "      <td>QQQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-06 00:00:00+00:00</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>8915</td>\n",
       "      <td>288.28</td>\n",
       "      <td>288.58</td>\n",
       "      <td>280.26</td>\n",
       "      <td>282.15</td>\n",
       "      <td>9180658.0</td>\n",
       "      <td>QQQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ts_event  rtype  publisher_id  instrument_id    open  \\\n",
       "0  2022-11-30 00:00:00+00:00     35             2           8933  281.65   \n",
       "1  2022-12-01 00:00:00+00:00     35             2           8929  293.00   \n",
       "2  2022-12-02 00:00:00+00:00     35             2           8919  293.43   \n",
       "3  2022-12-05 00:00:00+00:00     35             2           8916  292.04   \n",
       "4  2022-12-06 00:00:00+00:00     35             2           8915  288.28   \n",
       "\n",
       "     high     low   close      volume symbol  \n",
       "0  294.20  279.97  294.00  13716247.0    QQQ  \n",
       "1  295.75  290.88  293.24   8271505.0    QQQ  \n",
       "2  293.94  286.00  291.94   9893054.0    QQQ  \n",
       "3  292.26  286.15  288.02   6803353.0    QQQ  \n",
       "4  288.58  280.26  282.15   9180658.0    QQQ  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('databento/downloads/QQQ_data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for QQQ uploaded successfully to databento_ohlcv.QQQ.\n"
     ]
    }
   ],
   "source": [
    "upload_to_postgresql(df, 'QQQ', schema='databento_ohlcv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lean_datafeed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
